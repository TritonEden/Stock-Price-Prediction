{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset:\n",
      "         Date        Open        High         Low       Close   Adj Close  \\\n",
      "0  2015-01-02  151.500000  151.600006  148.500000  149.169998  149.169998   \n",
      "1  2015-01-05  148.809998  149.000000  146.779999  147.000000  147.000000   \n",
      "2  2015-01-06  147.639999  148.529999  146.110001  146.839996  146.839996   \n",
      "3  2015-01-07  147.940002  149.139999  147.649994  148.880005  148.880005   \n",
      "4  2015-01-08  150.600006  151.369995  150.509995  151.369995  151.369995   \n",
      "\n",
      "    Volume  \n",
      "0  3436400  \n",
      "1  4168800  \n",
      "2  4116100  \n",
      "3  4159100  \n",
      "4  4282100  \n",
      "\n",
      "Cleaned and normalized dataset:\n",
      "        Date      Open      High       Low     Close  Adj Close   Volume  \\\n",
      "0 2015-01-02  0.085192  0.079651  0.078951  0.077890   0.077890  3436400   \n",
      "1 2015-01-05  0.076825  0.071612  0.073508  0.071140   0.071140  4168800   \n",
      "2 2015-01-06  0.073186  0.070159  0.071388  0.070642   0.070642  4116100   \n",
      "3 2015-01-07  0.074119  0.072045  0.076261  0.076988   0.076988  4159100   \n",
      "4 2015-01-08  0.082392  0.078940  0.085311  0.084733   0.084733  4282100   \n",
      "\n",
      "   Volume_log  \n",
      "0   15.049935  \n",
      "1   15.243139  \n",
      "2   15.230417  \n",
      "3   15.240810  \n",
      "4   15.269954  \n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset (update the file path to match your Kaggle directory)\n",
    "file_path = './berkshire_hathaway_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display initial dataset structure\n",
    "print(\"Initial dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Logarithmic Scaling for Volume\n",
    "df['Volume_log'] = np.log1p(df['Volume'])  # log1p handles zero values effectively\n",
    "\n",
    "# Min-Max Scaling for Stock Prices (Open, High, Low, Close, Adj Close)\n",
    "scaler = MinMaxScaler()\n",
    "price_columns = ['Open', 'High', 'Low', 'Close', 'Adj Close']\n",
    "df[price_columns] = scaler.fit_transform(df[price_columns])\n",
    "\n",
    "# Display cleaned and normalized dataset\n",
    "print(\"\\nCleaned and normalized dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
